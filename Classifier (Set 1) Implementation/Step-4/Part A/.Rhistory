print(accuracy)
}
####################################################################################
#NeuralNet
accuracy=0
#We are choosing the BEST of the 5 accuracies obtained.
#Since, it was difficult to draw conclusion by parameter tuning using the AVG.
for(i in 1:5)
{
#Splitting the data
instances<-sample(1:nrow(scaled),size = 0.95*nrow(scaled))
trainingDataSet<-scaled[instances,]
testDataSet<-scaled[-instances,]
n <- names(trainingDataSet)
f	<- as.formula(paste("num	~",	paste(n[!n	%in%	"num"],	collapse	=	"	+	")))
#Building the model using training data
nn	<- neuralnet(f,data=trainingDataSet, hidden=3, rep=2)
#Predicting using test data
nn$result.matrix
pred	<- compute(nn,testDataSet[,1:13])
pred.scaled	<- pred$net.result *(max(given_Data$num)-min(given_Data$num))+min(given_Data$num)
real.values	<- (testDataSet$num)*(max(given_Data$num)-min(given_Data$num))+min(given_Data$num)
MSE.nn	<- sum((real.values	- pred.scaled)^2)/nrow(testDataSet)
#Accuracy
accuracy<- 100- MSE.nn
print(accuracy)
}
####################################################################################
#SVM
accuracy=0
#We are choosing the BEST of the 5 accuracies obtained.
#Since, it was difficult to draw conclusion by parameter tuning using the AVG.
for(i in 1:5)
{
#Splitting the data
instances<-sample(1:nrow(scaled),size = 0.8*nrow(scaled))
trainingDataSet<-given_Data[instances,]
testDataSet<-given_Data[-instances,]
n <- names(trainingDataSet)
f	<- as.formula(paste("num	~",	paste(n[!n	%in%	"num"],	collapse	=	"	+	")))
svmmodel<-svm(f,data=trainingDataSet,cost=100, gamma=0.00005, kernel = 'linear', type = "C-classification")
classVal<-predict(svmmodel,testDataSet,type="class")
#Accuracy using Confusion matrix
pred <- table(classVal,testDataSet$num)
table(classVal,testDataSet$num)
accuracy<-sum(diag(pred))/sum(pred)
print(accuracy)
}
####################################################################################
#Naive base
accuracy=0
#We are choosing the BEST of the 5 accuracies obtained.
#Since, it was difficult to draw conclusion by parameter tuning using the AVG.
for(i in 1:5)
{
#Splitting the data
instances<-sample(1:nrow(scaled),size = 0.95*nrow(scaled))
trainingDataSet<-scaled[instances,]
testDataSet<-scaled[-instances,]
nav_bayes <- naiveBayes(as.factor(num)~., data = trainingDataSet, threshold = 0.001, laplace = 0);
naivebayes.pred <- predict(nav_bayes, testDataSet[,1:13]);
pred <- table(naivebayes.pred, testDataSet[,14]);
#print(pred)
#accuracy
accuracy<-sum(diag(pred))/sum(pred)
print(accuracy)
}
####################################################################################
#NeuralNet
accuracy=0
#We are choosing the BEST of the 5 accuracies obtained.
#Since, it was difficult to draw conclusion by parameter tuning using the AVG.
for(i in 1:5)
{
#Splitting the data
instances<-sample(1:nrow(scaled),size = 0.80*nrow(scaled))
trainingDataSet<-scaled[instances,]
testDataSet<-scaled[-instances,]
n <- names(trainingDataSet)
f	<- as.formula(paste("num	~",	paste(n[!n	%in%	"num"],	collapse	=	"	+	")))
#Building the model using training data
nn	<- neuralnet(f,data=trainingDataSet, hidden=3, rep=2)
#Predicting using test data
nn$result.matrix
pred	<- compute(nn,testDataSet[,1:13])
pred.scaled	<- pred$net.result *(max(given_Data$num)-min(given_Data$num))+min(given_Data$num)
real.values	<- (testDataSet$num)*(max(given_Data$num)-min(given_Data$num))+min(given_Data$num)
MSE.nn	<- sum((real.values	- pred.scaled)^2)/nrow(testDataSet)
#Accuracy
accuracy<- 100- MSE.nn
print(accuracy)
}
####################################################################################
#Naive base
accuracy=0
#We are choosing the BEST of the 5 accuracies obtained.
#Since, it was difficult to draw conclusion by parameter tuning using the AVG.
for(i in 1:5)
{
#Splitting the data
instances<-sample(1:nrow(scaled),size = 0.80*nrow(scaled))
trainingDataSet<-scaled[instances,]
testDataSet<-scaled[-instances,]
nav_bayes <- naiveBayes(as.factor(num)~., data = trainingDataSet, threshold = 0.001, laplace = 0);
naivebayes.pred <- predict(nav_bayes, testDataSet[,1:13]);
pred <- table(naivebayes.pred, testDataSet[,14]);
#print(pred)
#accuracy
accuracy<-sum(diag(pred))/sum(pred)
print(accuracy)
}
###################################################################################
library(corrplot)
library(rpart)
library(e1071)
library(class)
library(neuralnet)
####################################################################################
#DATA AND PREPROCESSING
#Data Set
given_Data <- read.csv("processed.cleveland.data.txt",header = FALSE)
#Adding column Names to the dataset
colnames(given_Data) <- c("age","sex","cp","trestbps","chol","fbs","restecg","thalach","exang","oldpeak","slope","ca","thal","num")
#Converting dataset variables to a factor in R
given_Data$num <- factor(given_Data$num)
#Summary on the class labels
summary(given_Data$num)
#Dimensions of the dataset
dim(given_Data)
#Histogram on the classification labels
plot(given_Data$num)
#converting the data to numeric due to error in scaling - Error in colMeans(x, na.rm = TRUE) : 'x' must be numeric
given_Data$age<-as.numeric(given_Data$age)
given_Data$sex<-as.numeric(given_Data$sex)
given_Data$cp<-as.numeric(given_Data$cp)
given_Data$trestbps<-as.numeric(given_Data$trestbps)
given_Data$chol<-as.numeric(given_Data$chol)
given_Data$fbs<-as.numeric(given_Data$fbs)
given_Data$restecg<-as.numeric(given_Data$restecg)
given_Data$thalach<-as.numeric(given_Data$thalach)
given_Data$exang<-as.numeric(given_Data$exang)
given_Data$oldpeak<-as.numeric(given_Data$oldpeak)
given_Data$slope<-as.numeric(given_Data$slope)
given_Data$ca<-as.numeric(given_Data$ca)
given_Data$thal<-as.numeric(given_Data$thal)
given_Data$num<-as.numeric(given_Data$num)
#The dataset attributes have to be numeric for correlation plots
ModelCor <- cor(given_Data)
corrplot(ModelCor, method="circle")
corrplot(ModelCor, method="number")
#scaling the data
maxs =	apply(given_Data,	MARGIN	=	2,	max)
mins =	apply(given_Data,	MARGIN	=	2,	min)
scaled =	as.data.frame(scale(given_Data,	scale	=	maxs	- mins))
####################################################################################
#Decision Tree
#We are choosing the BEST of the 5 accuracies obtained.
#Since, it was difficult to draw conclusion by parameter tuning using the AVG.
for(i in 1:5)
{
#Splitting the data
instances<-sample(1:nrow(scaled),size = 0.85*nrow(scaled))
trainingDataSet<-scaled[instances,]
testDataSet<-scaled[-instances,]
#summary(testDataSet$num)
#Building the model using training data
treeModel<-rpart(as.factor(num)~.,method='class',data=trainingDataSet,control = rpart.control(minsplit = 60, cp = 0.009))
classval<- predict(treeModel,testDataSet,type=c("class"))
table(classval,testDataSet$num)
#Accuracy
accuracy <- sum(testDataSet$num == classval)/nrow(testDataSet)
print(accuracy)
}
####################################################################################
#Perceptron
accuracy=0
#We are choosing the BEST of the 5 accuracies obtained.
#Since, it was difficult to draw conclusion by parameter tuning using the AVG.
for(i in 1:5)
{
#Splitting the data
instances<-sample(1:nrow(scaled),size = 0.85*nrow(scaled))
trainingDataSet<-scaled[instances,]
testDataSet<-scaled[-instances,]
n <- names(trainingDataSet)
f	<- as.formula(paste("num	~",	paste(n[!n	%in%	"num"],	collapse	=	"	+	")))
#Building the model using training data
nn	<- neuralnet(f,data=trainingDataSet,hidden = 0,r =550, stepmax = 1e+8)
#Predicting using test data
nn$result.matrix
pred	<- compute(nn,testDataSet[,1:13])
pred.scaled	<- pred$net.result *(max(given_Data$num)-min(given_Data$num))+min(given_Data$num)
real.values	<- (testDataSet$num)*(max(given_Data$num)-min(given_Data$num))+min(given_Data$num)
MSE.nn	<- sum((real.values	- pred.scaled)^2)/nrow(testDataSet)
#Accuracy
accuracy<- 100- MSE.nn
print(accuracy)
}
####################################################################################
#NeuralNet
accuracy=0
library(corrplot)
library(rpart)
library(e1071)
library(class)
library(neuralnet)
####################################################################################
#DATA AND PREPROCESSING
#Data Set
given_Data <- read.csv("processed.cleveland.data.txt",header = FALSE)
#Adding column Names to the dataset
colnames(given_Data) <- c("age","sex","cp","trestbps","chol","fbs","restecg","thalach","exang","oldpeak","slope","ca","thal","num")
#Converting dataset variables to a factor in R
given_Data$num <- factor(given_Data$num)
#Summary on the class labels
summary(given_Data$num)
#Dimensions of the dataset
dim(given_Data)
#Histogram on the classification labels
plot(given_Data$num)
#converting the data to numeric due to error in scaling - Error in colMeans(x, na.rm = TRUE) : 'x' must be numeric
given_Data$age<-as.numeric(given_Data$age)
given_Data$sex<-as.numeric(given_Data$sex)
given_Data$cp<-as.numeric(given_Data$cp)
given_Data$trestbps<-as.numeric(given_Data$trestbps)
given_Data$chol<-as.numeric(given_Data$chol)
given_Data$fbs<-as.numeric(given_Data$fbs)
given_Data$restecg<-as.numeric(given_Data$restecg)
given_Data$thalach<-as.numeric(given_Data$thalach)
given_Data$exang<-as.numeric(given_Data$exang)
given_Data$oldpeak<-as.numeric(given_Data$oldpeak)
given_Data$slope<-as.numeric(given_Data$slope)
given_Data$ca<-as.numeric(given_Data$ca)
given_Data$thal<-as.numeric(given_Data$thal)
given_Data$num<-as.numeric(given_Data$num)
#The dataset attributes have to be numeric for correlation plots
ModelCor <- cor(given_Data)
corrplot(ModelCor, method="circle")
corrplot(ModelCor, method="number")
#scaling the data
maxs =	apply(given_Data,	MARGIN	=	2,	max)
mins =	apply(given_Data,	MARGIN	=	2,	min)
scaled =	as.data.frame(scale(given_Data,	scale	=	maxs	- mins))
####################################################################################
#Decision Tree
#We are choosing the BEST of the 5 accuracies obtained.
#Since, it was difficult to draw conclusion by parameter tuning using the AVG.
for(i in 1:5)
{
#Splitting the data
instances<-sample(1:nrow(scaled),size = 0.85*nrow(scaled))
trainingDataSet<-scaled[instances,]
testDataSet<-scaled[-instances,]
#summary(testDataSet$num)
#Building the model using training data
treeModel<-rpart(as.factor(num)~.,method='class',data=trainingDataSet,control = rpart.control(minsplit = 60, cp = 0.009))
classval<- predict(treeModel,testDataSet,type=c("class"))
table(classval,testDataSet$num)
#Accuracy
accuracy <- sum(testDataSet$num == classval)/nrow(testDataSet)
print(accuracy)
}
####################################################################################
#Perceptron
accuracy=0
#We are choosing the BEST of the 5 accuracies obtained.
#Since, it was difficult to draw conclusion by parameter tuning using the AVG.
for(i in 1:5)
{
#Splitting the data
instances<-sample(1:nrow(scaled),size = 0.85*nrow(scaled))
trainingDataSet<-scaled[instances,]
testDataSet<-scaled[-instances,]
n <- names(trainingDataSet)
f	<- as.formula(paste("num	~",	paste(n[!n	%in%	"num"],	collapse	=	"	+	")))
#Building the model using training data
nn	<- neuralnet(f,data=trainingDataSet,hidden = 0,r =550, stepmax = 1e+8)
#Predicting using test data
nn$result.matrix
pred	<- compute(nn,testDataSet[,1:13])
pred.scaled	<- pred$net.result *(max(given_Data$num)-min(given_Data$num))+min(given_Data$num)
real.values	<- (testDataSet$num)*(max(given_Data$num)-min(given_Data$num))+min(given_Data$num)
MSE.nn	<- sum((real.values	- pred.scaled)^2)/nrow(testDataSet)
#Accuracy
accuracy<- 100- MSE.nn
print(accuracy)
}
####################################################################################
#NeuralNet
accuracy=0
#We are choosing the BEST of the 5 accuracies obtained.
#Since, it was difficult to draw conclusion by parameter tuning using the AVG.
for(i in 1:5)
{
#Splitting the data
instances<-sample(1:nrow(scaled),size = 0.85*nrow(scaled))
trainingDataSet<-scaled[instances,]
testDataSet<-scaled[-instances,]
n <- names(trainingDataSet)
f	<- as.formula(paste("num	~",	paste(n[!n	%in%	"num"],	collapse	=	"	+	")))
#Building the model using training data
nn	<- neuralnet(f,data=trainingDataSet, hidden=3, rep=2)
#Predicting using test data
nn$result.matrix
pred	<- compute(nn,testDataSet[,1:13])
pred.scaled	<- pred$net.result *(max(given_Data$num)-min(given_Data$num))+min(given_Data$num)
real.values	<- (testDataSet$num)*(max(given_Data$num)-min(given_Data$num))+min(given_Data$num)
MSE.nn	<- sum((real.values	- pred.scaled)^2)/nrow(testDataSet)
#Accuracy
accuracy<- 100- MSE.nn
print(accuracy)
}
####################################################################################
#SVM
accuracy=0
#We are choosing the BEST of the 5 accuracies obtained.
#Since, it was difficult to draw conclusion by parameter tuning using the AVG.
for(i in 1:5)
{
#Splitting the data
instances<-sample(1:nrow(scaled),size = 0.85*nrow(scaled))
trainingDataSet<-given_Data[instances,]
testDataSet<-given_Data[-instances,]
n <- names(trainingDataSet)
f	<- as.formula(paste("num	~",	paste(n[!n	%in%	"num"],	collapse	=	"	+	")))
svmmodel<-svm(f,data=trainingDataSet,cost=100, gamma=0.00005, kernel = 'linear', type = "C-classification")
classVal<-predict(svmmodel,testDataSet,type="class")
#Accuracy using Confusion matrix
pred <- table(classVal,testDataSet$num)
table(classVal,testDataSet$num)
accuracy<-sum(diag(pred))/sum(pred)
print(accuracy)
}
####################################################################################
#Naive base
accuracy=0
#We are choosing the BEST of the 5 accuracies obtained.
#Since, it was difficult to draw conclusion by parameter tuning using the AVG.
for(i in 1:5)
{
#Splitting the data
instances<-sample(1:nrow(scaled),size = 0.85*nrow(scaled))
trainingDataSet<-scaled[instances,]
testDataSet<-scaled[-instances,]
nav_bayes <- naiveBayes(as.factor(num)~., data = trainingDataSet, threshold = 0.001, laplace = 0);
naivebayes.pred <- predict(nav_bayes, testDataSet[,1:13]);
pred <- table(naivebayes.pred, testDataSet[,14]);
#print(pred)
#accuracy
accuracy<-sum(diag(pred))/sum(pred)
print(accuracy)
}
####################################################################################
library(corrplot)
library(rpart)
library(e1071)
library(class)
library(neuralnet)
####################################################################################
#DATA AND PREPROCESSING
#Data Set
given_Data <- read.csv("processed.cleveland.data.txt",header = FALSE)
#Adding column Names to the dataset
colnames(given_Data) <- c("age","sex","cp","trestbps","chol","fbs","restecg","thalach","exang","oldpeak","slope","ca","thal","num")
#Converting dataset variables to a factor in R
given_Data$num <- factor(given_Data$num)
#Summary on the class labels
summary(given_Data$num)
#Dimensions of the dataset
dim(given_Data)
#Histogram on the classification labels
plot(given_Data$num)
#converting the data to numeric due to error in scaling - Error in colMeans(x, na.rm = TRUE) : 'x' must be numeric
given_Data$age<-as.numeric(given_Data$age)
given_Data$sex<-as.numeric(given_Data$sex)
given_Data$cp<-as.numeric(given_Data$cp)
given_Data$trestbps<-as.numeric(given_Data$trestbps)
given_Data$chol<-as.numeric(given_Data$chol)
given_Data$fbs<-as.numeric(given_Data$fbs)
given_Data$restecg<-as.numeric(given_Data$restecg)
given_Data$thalach<-as.numeric(given_Data$thalach)
given_Data$exang<-as.numeric(given_Data$exang)
given_Data$oldpeak<-as.numeric(given_Data$oldpeak)
given_Data$slope<-as.numeric(given_Data$slope)
given_Data$ca<-as.numeric(given_Data$ca)
given_Data$thal<-as.numeric(given_Data$thal)
given_Data$num<-as.numeric(given_Data$num)
#The dataset attributes have to be numeric for correlation plots
ModelCor <- cor(given_Data)
corrplot(ModelCor, method="circle")
corrplot(ModelCor, method="number")
#scaling the data
maxs =	apply(given_Data,	MARGIN	=	2,	max)
mins =	apply(given_Data,	MARGIN	=	2,	min)
scaled =	as.data.frame(scale(given_Data,	scale	=	maxs	- mins))
####################################################################################
#Decision Tree
#We are choosing the BEST of the 5 accuracies obtained.
#Since, it was difficult to draw conclusion by parameter tuning using the AVG.
for(i in 1:5)
{
#Splitting the data
instances<-sample(1:nrow(scaled),size = 0.95*nrow(scaled))
trainingDataSet<-scaled[instances,]
testDataSet<-scaled[-instances,]
#summary(testDataSet$num)
#Building the model using training data
treeModel<-rpart(as.factor(num)~.,method='class',data=trainingDataSet,control = rpart.control(minsplit = 60, cp = 0.009))
classval<- predict(treeModel,testDataSet,type=c("class"))
table(classval,testDataSet$num)
#Accuracy
accuracy <- sum(testDataSet$num == classval)/nrow(testDataSet)
print(accuracy)
}
####################################################################################
#Perceptron
accuracy=0
#We are choosing the BEST of the 5 accuracies obtained.
#Since, it was difficult to draw conclusion by parameter tuning using the AVG.
for(i in 1:5)
{
#Splitting the data
instances<-sample(1:nrow(scaled),size = 0.95*nrow(scaled))
trainingDataSet<-scaled[instances,]
testDataSet<-scaled[-instances,]
n <- names(trainingDataSet)
f	<- as.formula(paste("num	~",	paste(n[!n	%in%	"num"],	collapse	=	"	+	")))
#Building the model using training data
nn	<- neuralnet(f,data=trainingDataSet,hidden = 0,r =550, stepmax = 1e+8)
#Predicting using test data
nn$result.matrix
pred	<- compute(nn,testDataSet[,1:13])
pred.scaled	<- pred$net.result *(max(given_Data$num)-min(given_Data$num))+min(given_Data$num)
real.values	<- (testDataSet$num)*(max(given_Data$num)-min(given_Data$num))+min(given_Data$num)
MSE.nn	<- sum((real.values	- pred.scaled)^2)/nrow(testDataSet)
#Accuracy
accuracy<- 100- MSE.nn
print(accuracy)
}
####################################################################################
#NeuralNet
accuracy=0
#We are choosing the BEST of the 5 accuracies obtained.
#Since, it was difficult to draw conclusion by parameter tuning using the AVG.
for(i in 1:5)
{
#Splitting the data
instances<-sample(1:nrow(scaled),size = 0.95*nrow(scaled))
trainingDataSet<-scaled[instances,]
testDataSet<-scaled[-instances,]
n <- names(trainingDataSet)
f	<- as.formula(paste("num	~",	paste(n[!n	%in%	"num"],	collapse	=	"	+	")))
#Building the model using training data
nn	<- neuralnet(f,data=trainingDataSet, hidden=3, rep=2)
#Predicting using test data
nn$result.matrix
pred	<- compute(nn,testDataSet[,1:13])
pred.scaled	<- pred$net.result *(max(given_Data$num)-min(given_Data$num))+min(given_Data$num)
real.values	<- (testDataSet$num)*(max(given_Data$num)-min(given_Data$num))+min(given_Data$num)
MSE.nn	<- sum((real.values	- pred.scaled)^2)/nrow(testDataSet)
#Accuracy
accuracy<- 100- MSE.nn
print(accuracy)
}
####################################################################################
#SVM
accuracy=0
#We are choosing the BEST of the 5 accuracies obtained.
#Since, it was difficult to draw conclusion by parameter tuning using the AVG.
for(i in 1:5)
{
#Splitting the data
instances<-sample(1:nrow(scaled),size = 0.95*nrow(scaled))
trainingDataSet<-given_Data[instances,]
testDataSet<-given_Data[-instances,]
n <- names(trainingDataSet)
f	<- as.formula(paste("num	~",	paste(n[!n	%in%	"num"],	collapse	=	"	+	")))
svmmodel<-svm(f,data=trainingDataSet,cost=100, gamma=0.00005, kernel = 'linear', type = "C-classification")
classVal<-predict(svmmodel,testDataSet,type="class")
#Accuracy using Confusion matrix
pred <- table(classVal,testDataSet$num)
table(classVal,testDataSet$num)
accuracy<-sum(diag(pred))/sum(pred)
print(accuracy)
}
####################################################################################
#Naive base
accuracy=0
#We are choosing the BEST of the 5 accuracies obtained.
#Since, it was difficult to draw conclusion by parameter tuning using the AVG.
for(i in 1:5)
{
#Splitting the data
instances<-sample(1:nrow(scaled),size = 0.95*nrow(scaled))
trainingDataSet<-scaled[instances,]
testDataSet<-scaled[-instances,]
nav_bayes <- naiveBayes(as.factor(num)~., data = trainingDataSet, threshold = 0.001, laplace = 0);
naivebayes.pred <- predict(nav_bayes, testDataSet[,1:13]);
pred <- table(naivebayes.pred, testDataSet[,14]);
#print(pred)
#accuracy
accuracy<-sum(diag(pred))/sum(pred)
print(accuracy)
}
####################################################################################
print(trainingDataSet$num)
given_Data <- read.csv("processed.cleveland.data.txt",header = FALSE)
#Adding column Names to the dataset
colnames(given_Data) <- c("age","sex","cp","trestbps","chol","fbs","restecg","thalach","exang","oldpeak","slope","ca","thal","num")
#Converting dataset variables to a factor in R
given_Data$num <- factor(given_Data$num)
print(given_Data$num)
